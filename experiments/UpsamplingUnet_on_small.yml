optimizer: SGD
learning_rate: 1e-2

momentum: 0.9
weight_decay: 0 # easier to overfit # 1e-4
criterion: StableBCELoss

num_epochs: 101

log_iter_interval: 16
snapshot_epoch_interval: 25

train:
  batch_size: 1
  paddings:  !!python/tuple [0, 1]
  tile_size: !!python/tuple [768, 1024] # (height, width)
  hflip: True
  shift: True

test:
  batch_size: 1  # for easier visualize
  hflip: True
  shift: True
